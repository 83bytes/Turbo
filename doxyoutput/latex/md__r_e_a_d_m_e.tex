{\itshape C++11 metaprogramming library}

\subsection*{What is Turbo?}

Turbo is a library dessigned to provide compile-\/time utilities through \href{http://en.wikipedia.org/wiki/Template_metaprogramming}{\tt template metaprogramming}.

One of the key points of C++, and where its expresiveness power comes from, is its ability to define new language constructs and/or customize existing constructs, all leading in a simple and clear syntax (See for example D\+S\+E\+Ls).

But when dealing with the creation and/or manipulation of such constructs, nothing is simple nor clear. Template-\/meta-\/programming is powerfull, but suffers from a horrible syntax and the lack of high-\/level (meta)programming features. Some people claim that tmp seems like a compile-\/time pure functional language built inside C++ itself. But instead metaprogramming in C++ is more like a functional language with the worst syntax ever made (Despite L\+I\+S\+P?).

This library aims to provide high-\/level constructs to aid with the {\bfseries manipulation of the C++ type system}, and the creation and execution of {\bfseries complex computations at compile-\/time}; all with a clear and uniform syntax. Also the library takes advantage of such features and provides some usefull C++ (runtime) utilities, which are easy to implement thanks to Turbo.

\subsection*{What about Boost.\+M\+P\+L?}

\href{http://www.boost.org/doc/libs/1_55_0/libs/mpl/doc/index.html}{\tt Boost.\+M\+P\+L} is the de facto metaprogramming library for C++. But it suffers from two main problems which, in my oppinion, makes difficult to work with it\+:


\begin{DoxyItemize}
\item {\bfseries Is Boost}\+: The Boost libraries are one of the best C++ libraries in the world, but they base the implementation of their features on many many tricks they implemented (See Boost.\+Preprocessor, for example). The problem with Boost is that making a project depend on the Boost libraries could be a problem, its a huge library. My intention was to rely on standard features only, that is, something which works perfectly providing a C++11 compliant compiler only.
\item {\bfseries Boost.\+M\+P\+L was designed on the C++98 era}\+: C++11 is like a reboot of the language, and like in other parts of the language, metaprogramming in C++11 is far easier than in C++98/03. The problem is that M\+P\+L was written for/using C++98/03 and its design is based in some cumbersome constructs which have been cleared and/or simplified a lot in C++11. Specifically, template aliases are a huge advantage when doing template-\/meta-\/programming, and the Turbo library relies on that in all of its features.
\end{DoxyItemize}

\subsection*{Features}

At this time (April 2014) the library is being completely rewritten from scratch. The initial implementation suffers from some scalability issues due to problems (Bad design decissions?) on the base design and modules of the library.

To solve that problems, the library was completly redesigned, focusing the implementation on high-\/order metaprogramming facilities to make developing new features easy, and reduce (Avoid, if possible=) coupling on different features of the library.

The reimplementation of the library is being developed at the \href{https://github.com/Manu343726/Turbo/tree/reboot}{\tt `reboot` branch}. Its (currently) focused in a simple set of high-\/order features\+:

\subsubsection*{Uniform expression evaluation facilities}

The goal is to create a way to evaluate any kind of expression the library could work with. By convention, this library works with types only. There are no templates with value parameters, basic values are provided through boxing using wrappers like {\ttfamily std\+::integral\+\_\+constant}. {\itshape Note that this is not required inside the implementation itself}. So an expression could be\+:
\begin{DoxyEnumerate}
\item A simple value (Like {\ttfamily int}).
\item A {\itshape parametrized-\/expression}\+: A parametrized expression is just an expression composed from a set of components. Because this is a template metaprogramming library, the way to build expressions is through templates. So a parametrized expressions refers to any kind of template.
\item A {\itshape functional expression}\+: This is a type of parametrized expression dessigned to return a value from a set of parameters. That is, a function. This library assumes that any expression with a {\ttfamily result} type member is a function.
\end{DoxyEnumerate}

``` cpp //\+A simple expression using e1 = int; //e1 is a simple expression

//\+A functional expression using e2 = tml\+::function$<$int$>$; //e2 is a functional expression

//\+A more complex expression (A functional expression) using e3 = tml\+::transform$<$tml\+::list$<$int,float,double$>$,tml\+::size\+\_\+of$<$\+\_\+1$>$$>$; ```

To evaluate an expression, one should evaluate the entire set of parameters of a parametrized expression, and return the result if the expression is a functional expression. Thats what {\ttfamily tml\+::eval} is dessigned for\+:

``` cpp //\+Just a simple identity metafunction\+: template$<$typename T$>$ struct identity \{ using result = T; \};

using expression = identity$<$int$>$; using result = tml\+::eval$<$expression$>$; //\+Compute the result of evaluating the expression. using result = tml\+::eval$<$identity$<$identity$<$int$>$$>$$>$; //result is int ```

Also, {\ttfamily tml\+::eval} could be used to take an expression and evaluate it with a new set of argumments. Following with the example above\+: \begin{DoxyVerb}using binded = tml::eval<identity<int>,float>; //We evaluate identity<> with float instead of int as parameter
\end{DoxyVerb}


Or one could fill the expression with placeholders and evaluate the expression later when the argumments are aviable (Lazy evaluation)\+: \begin{DoxyVerb}using expression = f<_1,_2,_3>; //_1,_2, and _3 are placeholders
...
using result = tml::eval<expression,float,int,double>;
\end{DoxyVerb}


Because the library wrks with types only, lazy evaluation of metafunctions should be done filling the metafunction with placeholders to properly instantiate it (See the example above). Turbo provides the {\ttfamily \hyperlink{structtml_1_1lazy}{tml\+::lazy}} template, dessigned to take a template parameter storing it, making possible to instantiate the template later\+: \begin{DoxyVerb}using t = tml::lazy<tml::function>; //t stores a tml::function metafunction
using instance = tml::lazy_instance<t,int>; //instance is tml::function<int>
\end{DoxyVerb}


Also {\ttfamily \hyperlink{structtml_1_1lazy}{tml\+::lazy}} could be used to do lazy evaluation of metafunctions. For example\+: \begin{DoxyVerb}using t = tml::lazy<tml::function>;
using result = tml::eval<t,int>; //Result is int (The result of evaluating tml::function<int>)
\end{DoxyVerb}


Finally {\ttfamily tml\+::eval} abuses of function types and specializes itself to handle function types like {\ttfamily F(A\+R\+G\+S...)} as a metafunction call, where {\ttfamily F} is a functional expression\+: \begin{DoxyVerb}using F = tml::lambda<_1 , tml::add<_1,_1>>;
using i = tml::Int<1>;

using r = tml::eval<F(i)>;
\end{DoxyVerb}


For more information see the documentation inside {\ttfamily \hyperlink{eval_8hpp_source}{eval.\+hpp}}.

\subsubsection*{Haskell-\/like let expressions}

{\ttfamily tml\+::eval} allows you to evaluate an exsisting expression with other argumments, but it hasn't enought power to be usable in all situations. For example, {\ttfamily tml\+::eval} only binds parameters of the main scope, so an expression with nested parametrized expressions can only be reevaluated specifying the most enclosing parameter (See the tml\+::eval binding examples above).

Turbo probides {\ttfamily tml\+::let}, a high-\/order metafunction similar to haskell's {\ttfamily let} Its purpose is to subsitute a value on an expression, given an specifiec variable to bind the value with\+: \begin{DoxyVerb}struct X{}; //A "variable"

using expression = tml::let<X,int,tml::function<X>>; // expression is "tml::function<int>"
\end{DoxyVerb}


The power of let comes from its ability to parse the entire expression recursively, subsituting all ocurrences of the variable with the specified value\+: \begin{DoxyVerb}using expression = tml::let<X,float,f<X,int,tml::function<g<X,X>>>>; //Expression is f<float,int,tml::function<g<float,float>>>
\end{DoxyVerb}


Finally, Turbo extends that concept providing the {\ttfamily tml\+::multi\+\_\+let} template, a template dessigned as a let of multiple variables\+: \begin{DoxyVerb}using expression = tml::multi_let<X,Y,Z, //variables
                                  int,char,double, //values
                                  f<X,g<Y,Z>> //expression
                                 >;
\end{DoxyVerb}


{\ttfamily tml\+::multi\+\_\+let} works currifying the multiple variable let into a chain of nested {\ttfamily tml\+::let} expressions.

\subsubsection*{Lambda expressions\+:}

The ability of substituting a value in an expression provided by {\ttfamily tml\+::let} makes possible to create lambda expressions without any special effort. Turbo provides the {\ttfamily tml\+::lambda} template\+: \begin{DoxyVerb}//Gets a list with the sizes of the specified types
using result = tml::transform<tml::lambda<_1,tml::size_of<_1>>,tml::list<float,int,double>>;
\end{DoxyVerb}


Multiple-\/variable lambda expressions are provided too\+: \begin{DoxyVerb}//Returns true if at least one element of the SEQUENCE evaluates the predicate P to true
template<typename P , typename SEQUENCE>
using any_of = tml::foldl<tml::multi_lambda<_1,_2 , tml::logical_or<_1,tml::eval<P,_2>>>,SEQUENCE>;
\end{DoxyVerb}


\subsubsection*{High-\/order algorithms. Lists and iterators\+:}

Turbo implements a set of high-\/order metafunctions as algorithms provided by the {\ttfamily \hyperlink{algorithm_8hpp_source}{algorithm.\+hpp}} header. Those algorithms mimic the most common functional high-\/order functions to provide building blocks for the rest of the library\+: \begin{DoxyVerb}//Compute the adition of a set of numbers at compile-time
template<typename... Ns>
using sum = tml::foldl<tml::lambda<_1,_2 , tml::add<_1,_2>>,tml::zero,tml::list<Ns...>>;
\end{DoxyVerb}


Turbo is a C++ library, but since template-\/meta-\/programming seems like a functional language, Turbo takes inspiration from functional languages such as Haskell. For algorithms, C++ uses an iterator approach, when Haskell uses lists instead. Both approaches has advantages and cons, so what approach we should use?

Turbo doesn't choose between, instead implements both using exactly the same interface! Turbo algorithms are designed to work with sequences, and that sequences could be represented via typelists ({\ttfamily \hyperlink{structtml_1_1list}{tml\+::list}}) or iterators\+: \begin{DoxyVerb}using numbers = tml::integer_list<1,2,3,4,5>;

using squared = tml::map<tml::lambda<_1 , tml::mul<_1,_1>>,numbers>;
using squared = tml::map<tml::lambda<_1 , tml::mul<_1,_1>>,tml::begin<numbers>,tml::end<numbers>>;
\end{DoxyVerb}


The library provides the header {\ttfamily \hyperlink{iterator_8hpp_source}{iterator.\+hpp}}, which implements metafunctions for iterators manipulation, such as {\ttfamily tml\+::begin}, {\ttfamily tml\+::end} , {\ttfamily tml\+::rbegin}, {\ttfamily tml\+::next} , {\ttfamily tml\+::deref} , etc. The header provides the declaration of the metafunctions, aliases, and the implementation metafunctions, all ready to be highly customizable by the user. This allows to write iterator-\/ready custom types specializing a small set of metafunctions only. When its done, everything automagically works!

By default Turbo provides an iterator implementation for typelists (See the example above) and integral values (See the {\ttfamily numeric\+\_\+iterators.\+hpp} header)\+: \begin{DoxyVerb}//Returns a list filled with the numbers on the interval [begin,end)
template<int begin , int end>
using integer_range = tml::map<tml::function<_>,
                               tml::forward_iterators::make_int<begin>,
                               tml::forward_iterators::make_int<end>
                              >;
\end{DoxyVerb}


\subsubsection*{T\+M\+P-\/aware static asserting\+:}

The standard {\ttfamily static\+\_\+assert()} expects a boolean value as asserting condition. In mostly situations (Even using the Standard Library metaprogramming facilities only) that condition comes in the form of a boolean type (Like {\ttfamily std\+::integral\+\_\+constant$<$bool,true$>$}). Turbo implements the macro {\ttfamily T\+U\+R\+B\+O\+\_\+\+A\+S\+S\+E\+R\+T()} which is dessigned to work with such types without needing to extract the value via the {\ttfamily \+::value} member\+: \begin{DoxyVerb}TURBO_ASSERT( (std::is_integral<int>) , "What happened????" );
\end{DoxyVerb}


\subsubsection*{Compilation-\/time static warning\+:}

The only standard way to throw warnings during compilation is the {\ttfamily \#warning} macro. But this warnings are checked during preprocessing time, and what a C++ (meta)programmer needs is a way to generate warnings depending on compile-\/time values and/or templates.

Turbo implements a {\ttfamily S\+T\+A\+T\+I\+C\+\_\+\+W\+A\+R\+N\+I\+N\+G()} macro, which generates a warning at template instantation phase. This feature is based in a {\ttfamily deprecated} attribute trick, which will be standard in C++14. At this time, Turbo uses compiler-\/specific attributes.

\subsubsection*{Uniform multiple-\/\+S\+F\+I\+N\+A\+E facilities\+:}

The Standard template to do S\+F\+I\+N\+A\+E, {\ttfamily std\+::enable\+\_\+if}, disables the instantation of a template if a certain boolean condition is not guaranteed. As in the {\ttfamily static\+\_\+assert()} case explained above, {\ttfamily std\+::enable\+\_\+if} expects a boolean value as condition. Also, the member type {\ttfamily \+::type} of {\ttfamily std\+::enable\+\_\+if} should be explicitly referenced via the common and cumbersome {\ttfamily typename \+::type} construction.

Turbo provides the macros {\ttfamily T\+U\+R\+B\+O\+\_\+\+E\+N\+A\+B\+L\+E\+\_\+\+I\+F()} and {\ttfamily T\+U\+R\+B\+O\+\_\+\+D\+I\+S\+A\+B\+L\+E\+\_\+\+I\+F()}, which makes S\+F\+I\+N\+A\+E clean and easy. For example\+: \begin{DoxyVerb}template<typename T , typename SFINAE_FLAG = tml::sfinae_result>
struct f;

template<typename T>
struct f<T , TURBO_ENABLE_IF( std::is_floating_point<T> )>
{};
\end{DoxyVerb}


There are cases where a template should be enabled/disabled depending in many conditions. This could be achieved passing a complex boolean expression to {\ttfamily std\+::enable\+\_\+if} (Or {\ttfamily T\+U\+R\+B\+O\+\_\+\+E\+N\+A\+B\+L\+E/\+D\+I\+S\+A\+B\+L\+E\+\_\+\+I\+F()}). Instead Turbo implements a so-\/called {\itshape sfinae container}, that is, a template dessigned to store multiple S\+F\+I\+N\+A\+E entities like {\ttfamily std\+::enable\+\_\+if} and behave itself as a big {\ttfamily enable\+\_\+if}. That template is enabled (ie declares a {\ttfamily \+::type} member) if and only if all the S\+F\+I\+N\+A\+E entities passed are enabled.

Also Turbo provies some macros, {\ttfamily T\+U\+R\+B\+O\+\_\+\+S\+F\+I\+N\+A\+E\+\_\+\+A\+L\+L()} , {\ttfamily T\+U\+R\+B\+O\+\_\+\+S\+F\+I\+N\+A\+E\+\_\+\+A\+N\+Y()}, {\ttfamily E\+N\+A\+B\+L\+E\+\_\+\+I\+F()}, and {\ttfamily D\+I\+S\+A\+B\+L\+E\+\_\+\+I\+F()} to build such sfinae containers easily. The combination of these features makes possible to write multiple-\/condition S\+F\+I\+N\+A\+E expressions in a clear and concise syntax\+: \begin{DoxyVerb}//Following with the f example above, now we define another f specialization:

template<typename T>
struct f<T , TURBO_SFINAE_ALL( DISABLE_IF( std::is_floating_point<T> ),
                               ENABLE_IF( std::is_default_constructible<T>)
                             )>
{

};
\end{DoxyVerb}


\subsubsection*{Runtime access to compile-\/time computations via the {\ttfamily tml\+::to\+\_\+runtime$<$T$>$()} function\+:}

The function {\ttfamily tml\+::to\+\_\+runtime$<$T$>$()} returns a runtime constant equivalent to the spefied compile-\/time value {\ttfamily T}. Its dessigned to provide a clear interface between the compile-\/time and runtime sides of a program. For example\+: \begin{DoxyVerb}//Compute the range of ints [10,20) at compile-time
using numbers = tml::integer_range<10,20>;

//Print that numbers at runtime:
for( int i : tml::to_runtime<numbers>() )
    std::cout << i << " ";
\end{DoxyVerb}


\begin{quote}
10 11 12 13 14 15 16 17 18 19 \end{quote}


\subsubsection*{Compile-\/time floating-\/point arithmetic\+:}

Turbo implements its own floating-\/point type to perform compile-\/time computations. The implementation doesn't follow any specific standard (i.\+e. I\+E\+E\+E 754), its only a working (on...) implementation with the following characteristics\+:


\begin{DoxyItemize}
\item 32 bit mantissa with no implicit extra 1 (The mantissa is 32 bits wide, and the precission of the resulting number is 32 bits too. Thats done to simplify debugging).
\item 16 bit exponent.
\end{DoxyItemize}

``` cpp using one = \hyperlink{structtml_1_1floating_1_1number}{tml\+::floating\+::number}$<$tml\+::floating\+::sign\+\_\+t\+::positive , -\/31 , 0x80000000$>$; using two = tml\+::eval$<$tml\+::add$<$one,one$>$$>$; //two is \mbox{[}+$\vert$-\/30$\vert$0x80000000\mbox{]} using three = tml\+::eval$<$tml\+::add$<$one,two$>$$>$; //three is \mbox{[}+$\vert$-\/30$\vert$0x\+C0000000\mbox{]} ```

Several metafunction are provided for easy initialization of floating-\/point values\+:

```cpp using two = tml\+::floating\+::integer$<$2$>$; using sqrt\+\_\+two = tml\+::eval$<$tml\+::sqrt$<$two$>$$>$; using pi = tml\+::floating\+::decimal$<$3,141592654$>$;

int main() \{ std\+::cout $<$$<$ tml\+::to\+\_\+string$<$two$>$() $<$$<$ std\+::endl $<$$<$ tml\+::to\+\_\+runtime$<$two$>$() $<$$<$ std\+::endl;

std\+::cout $<$$<$ tml\+::to\+\_\+string$<$sqrt\+\_\+two$>$() $<$$<$ std\+::endl $<$$<$ tml\+::to\+\_\+runtime$<$sqrt\+\_\+two$>$() $<$$<$ std\+::endl;

std\+::cout $<$$<$ tml\+::to\+\_\+string$<$pi$>$() $<$$<$ std\+::endl $<$$<$ tml\+::to\+\_\+runtime$<$pi$>$() $<$$<$ std\+::endl; \} ```

\begin{quote}
\mbox{[}+$\vert$-\/30$\vert$10000000000000000000000000000000\mbox{]} 2 \mbox{[}+$\vert$-\/31$\vert$10110101000001001111001100110110\mbox{]} 1.\+41421 \mbox{[}+$\vert$-\/30$\vert$11001001000011111101101010100010\mbox{]} 3.\+14159 \end{quote}


The library is designed to do all the required computations at compile-\/time with zero runtime overhead when using the resutls. That means the floating-\/point values (Actually stored as {\ttfamily double}s on the runtime side) should be completely aviable and known at compile-\/time.

Given this code, which computes N (10 in the example) consecutive floating-\/point numbers at compile-\/time\+:

```cpp template$<$std\+::size\+\_\+t N$>$ using generate\+\_\+numbers = tml\+::foldl$<$tml\+::lambda$<$\+\_\+1,\+\_\+2 , tml\+::lists\+::func\+::push\+\_\+front$<$\+\_\+1,\hyperlink{structtml_1_1add}{tml\+::add}$<$tml\+::lists\+::func\+::head$<$\+\_\+1$>$,tml\+::floating\+::integer$<$1$>$$>$$>$$>$ , \hyperlink{structtml_1_1list}{tml\+::list}$<$tml\+::floating\+::integer$<$0$>$$>$ , tml\+::integral\+\_\+forward\+\_\+iterators\+::make\+\_\+size\+\_\+t$<$0$>$ , tml\+::integral\+\_\+forward\+\_\+iterators\+::make\+\_\+size\+\_\+t$<$\+N$>$$>$;

int main() \{ using numbers = generate\+\_\+numbers$<$10$>$;

for( double n \+: tml\+::to\+\_\+runtime$<$numbers$>$() ) std\+::cout $<$$<$ n $<$$<$ std\+::endl;

\} ``{\ttfamily  Yields to the following code for the}tml\+::to\+\_\+runtime()` instance\+:

```asm \+\_\+\+Z\+N3tml4impl10to\+\_\+runtime\+I\+N\+S\+\_\+4list\+I\+J\+N\+S\+\_\+8floating6number\+I\+L\+N\+S3\+\_\+6sign\+\_\+t\+E1\+E\+Lsn28\+E\+Lj2684354560\+E\+E\+E\+N\+S4\+\_\+\+I\+L\+S5\+\_\+1\+E\+Lsn28\+E\+Lj2415919104\+E\+E\+E\+N\+S4\+\_\+\+I\+L\+S5\+\_\+1\+E\+Lsn28\+E\+Lj2147483648\+E\+E\+E\+N\+S4\+\_\+\+I\+L\+S5\+\_\+1\+E\+Lsn29\+E\+Lj3758096384\+E\+E\+E\+N\+S4\+\_\+\+I\+L\+S5\+\_\+1\+E\+Lsn29\+E\+Lj3221225472\+E\+E\+E\+N\+S4\+\_\+\+I\+L\+S5\+\_\+1\+E\+Lsn29\+E\+Lj2684354560\+E\+E\+E\+N\+S4\+\_\+\+I\+L\+S5\+\_\+1\+E\+Lsn29\+E\+Lj2147483648\+E\+E\+E\+N\+S4\+\_\+\+I\+L\+S5\+\_\+1\+E\+Lsn30\+E\+Lj3221225472\+E\+E\+E\+N\+S4\+\_\+\+I\+L\+S5\+\_\+1\+E\+Lsn30\+E\+Lj2147483648\+E\+E\+E\+N\+S4\+\_\+\+I\+L\+S5\+\_\+1\+E\+Lsn31\+E\+Lj2147483648\+E\+E\+E\+N\+S4\+\_\+\+I\+L\+S5\+\_\+1\+E\+Lsn31\+E\+Lj0\+E\+E\+E\+E\+E\+E\+E5array\+E\+: .quad 4621819117588971520 \# double 1.\+000000e+01 .quad 4621256167635550208 \# double 9.\+000000e+00 .quad 4620693217682128896 \# double 8.\+000000e+00 .quad 4619567317775286272 \# double 7.\+000000e+00 .quad 4618441417868443648 \# double 6.\+000000e+00 .quad 4617315517961601024 \# double 5.\+000000e+00 .quad 4616189618054758400 \# double 4.\+000000e+00 .quad 4613937818241073152 \# double 3.\+000000e+00 .quad 4611686018427387904 \# double 2.\+000000e+00 .quad 4607182418800017408 \# double 1.\+000000e+00 .quad 0 \# double 0.\+000000e+00 .size \+\_\+\+Z\+N3tml4impl10to\+\_\+runtime\+I\+N\+S\+\_\+4list\+I\+J\+N\+S\+\_\+8floating6number\+I\+L\+N\+S3\+\_\+6sign\+\_\+t\+E1\+E\+Lsn28\+E\+Lj2684354560\+E\+E\+E\+N\+S4\+\_\+\+I\+L\+S5\+\_\+1\+E\+Lsn28\+E\+Lj2415919104\+E\+E\+E\+N\+S4\+\_\+\+I\+L\+S5\+\_\+1\+E\+Lsn28\+E\+Lj2147483648\+E\+E\+E\+N\+S4\+\_\+\+I\+L\+S5\+\_\+1\+E\+Lsn29\+E\+Lj3758096384\+E\+E\+E\+N\+S4\+\_\+\+I\+L\+S5\+\_\+1\+E\+Lsn29\+E\+Lj3221225472\+E\+E\+E\+N\+S4\+\_\+\+I\+L\+S5\+\_\+1\+E\+Lsn29\+E\+Lj2684354560\+E\+E\+E\+N\+S4\+\_\+\+I\+L\+S5\+\_\+1\+E\+Lsn29\+E\+Lj2147483648\+E\+E\+E\+N\+S4\+\_\+\+I\+L\+S5\+\_\+1\+E\+Lsn30\+E\+Lj3221225472\+E\+E\+E\+N\+S4\+\_\+\+I\+L\+S5\+\_\+1\+E\+Lsn30\+E\+Lj2147483648\+E\+E\+E\+N\+S4\+\_\+\+I\+L\+S5\+\_\+1\+E\+Lsn31\+E\+Lj2147483648\+E\+E\+E\+N\+S4\+\_\+\+I\+L\+S5\+\_\+1\+E\+Lsn31\+E\+Lj0\+E\+E\+E\+E\+E\+E\+E5array\+E, 88 ``` {\itshape We all hate C++ mangling, isn't?}

Which is exactly the expected behaviour\+: Floating-\/point values injected into the executable, with no runtime overhead.

\subsection*{Known issues\+:}

The features explained above have some implementation issues (Working on...)\+:


\begin{DoxyItemize}
\item {\bfseries Template specialization priority issues. A I\+S\+O C++ Standard bug?}\+: The initial implementation of {\ttfamily tml\+::eval} consisted on three different cases (Partial specializations), one for each kind of expression the library is cappable of evaluate\+:
\begin{DoxyEnumerate}
\item {\bfseries Simple values}\+: The result of evaluating a value is the value itself \begin{DoxyVerb} using result = tml::eval<tml::Int<0>>; //result is Int<0>
 using result = tml::eval<int>; //result is int
\end{DoxyVerb}

\item {\bfseries Parametrized expressions}\+: Parametrized expressions are not functions, but their parameters could be anything, so they must be evaluated \begin{DoxyVerb} using vector = tml::eval<std::vector<tml::function<int>>>; // vector is std::vector<int>
\end{DoxyVerb}

\item {\bfseries Functional expressions}\+: Same as parametrized expressions, but they have a result which should be computed (Extracted) \begin{DoxyVerb} using myint = tml::eval<tml::function<int>>; //myint is int
\end{DoxyVerb}

\item {\bfseries Functional expressions with binded argumments}\+: {\ttfamily tml\+::eval} could be used to reevaluate an existing (Instanced) functional expression with a new set of parameters \begin{DoxyVerb} using result = tml::eval<tml::function<int>,double>; //result is double
\end{DoxyVerb}

\end{DoxyEnumerate}

In addition to this generic cases, the user could explicitly specialize the implementation of {\ttfamily tml\+::eval} (The internal template {\ttfamily \hyperlink{structtml_1_1impl_1_1eval}{tml\+::impl\+::eval}}) to make {\ttfamily tml\+::eval} work in a custom and specific way. For example\+: \begin{DoxyVerb} struct foo {};

 //We customize tml::eval saying the result of evaluating 'foo' is 'int'
 template<>
 struct eval<foo> : public tml::function<int>
 {};
\end{DoxyVerb}


When the specialized expression is complex (Like a template {\ttfamily template$<$typename T$>$ struct bar\{\};}) that specialization has conflicts with the default generic specializations. The {\itshape common sense} says that our custom specialization should be instanced, because {\ttfamily bar$<$T$>$} is more specialized than {\ttfamily F$<$T$>$} (The generic functional case). Instead, the generic specialization is instanced or the compilation fails due to ambiguous template specializations (Depending on the compiler).

This situation \href{http://stackoverflow.com/questions/23393962/partial-template-template-based-specialization-vs-explicit-partial-template-spec}{\tt was discussed} for two weeks, and after some effort we conclused this is an issue on the wording of the I\+S\+O Standard, specifically\+:
\end{DoxyItemize}

\begin{quote}
If for each type being considered a given template is at least as specialized for all types, and more specialized for some set of types and the other template is not more specialized for any types, or \{the other template\} is not at least as specialized for any types, then the given template is more specialized than the other template. \end{quote}


An ambiguity problem very similar to \href{http://www.open-std.org/jtc1/sc22/wg21/docs/cwg_active.html#1705}{\tt an official I\+S\+O C++ issue} which has no official resolution (At June 2014).

{\itshape The situation was solved using S\+F\+I\+N\+A\+E and a custom registry metafunction which specifies if a certain kind of expression overrides the default behaviour of {\ttfamily tml\+::eval}. Note that its only a workaround, the bug on the template specialization rules is still there.}


\begin{DoxyItemize}
\item $\ast$$\ast${\ttfamily \hyperlink{structtml_1_1impl_1_1multi__lambda}{tml\+::impl\+::multi\+\_\+lambda}} evaluation doesn't work on G\+C\+C$\ast$$\ast$\+: The multiple-\/variable lambda template is defined as follows\+: \begin{DoxyVerb}  template<typename... VARIABLES , typename BODY>
  struct multi_lambda
  {
      template<typename... ARGS>
      using result = tml::eval<tml::multi_let<VARIABLES...,
                                              ARGS...,
                                              BODY
                                             >
                              >;
  };
\end{DoxyVerb}


Later {\ttfamily \hyperlink{structtml_1_1impl_1_1multi__lambda}{tml\+::impl\+::multi\+\_\+lambda}} overrides {\ttfamily tml\+::eval} to call the {\ttfamily \+::result} template alias properly\+: \begin{DoxyVerb}  template<typename... VARIABLES , typename BODY>
  struct overrides_eval<tml::impl::multi_lambda<VARIABLES...,BODY>> : public tml::true_type
  {};

  template<typename... VARIABLES , typename BODY , typename... ARGS>
  struct eval<tml::impl::multi_lambda<VARIABLES...,BODY>,tml::list<ARGS...>> :
     public tml::function<typename tml::impl::multi_lambda<VARIABLES...,BODY>::template result<ARGS...>>
  {};
\end{DoxyVerb}


{\itshape The evaluation of that lambda does not work on G\+C\+C. After some discussions and tests I'm sure this code is valid, seems like a G\+C\+C bug. This project was reconfigured to use the L\+L\+V\+M/\+C\+Lang toolchain, where this code works perfectly.}
\item {\bfseries The {\ttfamily T\+U\+R\+B\+O\+\_\+\+A\+S\+S\+E\+R\+T()} macro overloading doesn't work on L\+L\+V\+M/\+C\+Lang}\+: {\ttfamily T\+U\+R\+B\+O\+\_\+\+A\+S\+S\+E\+R\+T()} is a macro \char`\"{}overloaded\char`\"{}, making possible to pass one or two parameters depending on the use case. The macro overloading is an old trick to define macros with different number of parameters, but with the same name. {\ttfamily T\+U\+R\+B\+O\+\_\+\+A\+S\+S\+E\+R\+T()} was implemented and tested using G\+C\+C 4.\+8.\+2, but the overloading doesn't work properly on L\+L\+V\+M/\+C\+Lang toolchain for some reason.

{\itshape Currently fixed, was a bug on the {\ttfamily S\+E\+L\+E\+C\+T\+\_\+\+A\+R\+G\+\_\+3(...)} macro.}
\item {\bfseries Lambda body and placeholders evaluation}\+: As explained above in the {\ttfamily Features} entry, Turbo implements lambda expressions as Haskell-\/like let expressions where the lambda variables are substituted with the value of the parameters at the point of lambda evaluation\+: \begin{DoxyVerb} using l = tml::lambda<_1 , tml::function<_1>>;
 using result = tml::eval<l,int>; //result is int
\end{DoxyVerb}


Even if {\ttfamily tml\+::eval} is specialized to take care of placeholders, there are cases when expressions depending on {\ttfamily tml\+::eval} evaluation are not correctly evaluated because they have placeholders. Consider this example\+: \begin{DoxyVerb} template<typename F , typename SEQ>
 using any_of = tml::foldl<tml::lambda<_1,_2 , logical_or<_1,tml::eval<F,_2>>>,tml::false_type,SEQ>;
\end{DoxyVerb}


This sentence defines a metafunction {\ttfamily any\+\_\+of}, which returns true if almost one element of a sequence evaluates to true certain predicate. Its implemented using a metafunction provided by the Turbo \char`\"{}algorithm.\+hpp\char`\"{} header, a Haskell-\/like {\ttfamily foldl} metafunction (Similar to {\ttfamily std\+::accumulate()}). The combination metafunction passed to {\ttfamily tml\+::foldl} is written in the form of a binary lambda expression, which computes the logical or between the current state of the computation and the current element of the sequence. \char`\"{}\+Readable\char`\"{} functional programming at compile-\/time in C++. Cool, isn't?

But that doesn't work. Note that the {\ttfamily tml\+::eval} written inside the lambda body is instanced (Executed) before the substitution of the lambda variables (The placeholders). To deal with that situations, a template {\ttfamily \hyperlink{structtml_1_1delayed__eval}{tml\+::delayed\+\_\+eval}} ({\ttfamily tml\+::deval}) was designed to hold a {\ttfamily tml\+::eval}-\/like expression inside let expressions. During the let execution, {\ttfamily \hyperlink{structtml_1_1delayed__eval}{tml\+::delayed\+\_\+eval}} is substituted by {\ttfamily tml\+::eval} {\bfseries after variable substitution}. The correct {\ttfamily tml\+::any} implementation should be\+: \begin{DoxyVerb}  template<typename P , typename SEQUENCE>
  using any = tml::foldl<P,tml::lambda<_1,_2 , tml::logical_or<_1,tml::deval<P,_2>>>>,tml::false_type,SEQUENCE>;
\end{DoxyVerb}


This solution successfully solved the problem on unary lambdas, but it doesn't work on multiple-\/variable lambda expressions, probably because of the curryfication process.

{\itshape Fixed, it was a bug on the currifier}
\end{DoxyItemize}

\subsection*{R\+E\+A\+D\+M\+E content of the original library implementation\+:}

Turbo provides a set of features to simplify type manipulation and compile-\/time computations\+:

\subsubsection*{Portable {\ttfamily to\+\_\+string()} function to print type names at runtime\+:}

Turbo implements demangling for the most common compilers\textsuperscript{1} to provide a function which returns the {\ttfamily std\+::string} representation of a type. For example\+: \begin{DoxyVerb}#include "to_string.hpp" 
#include <iostream>
#include <vector>

int main()
{
    std::cout << mpl::to_string<std::vector<int>>() << std::endl;
}
\end{DoxyVerb}


Output\+: \begin{quote}
{\ttfamily vector$<$int$>$} \end{quote}


$\ast$\mbox{[}1\mbox{]} G\+C\+C and M\+S\+V\+C only demangling implementation yet.$\ast$

\subsubsection*{Compile-\/time basic types wrappers\+: Compile-\/time arithmetic}

Turbo provides a set of predefined templates which are equivalent to the most common C++ basic types, such as {\ttfamily bool}, {\ttfamily char}, {\ttfamily integer}, etc\+: {\ttfamily mpl\+::boolean}, {\ttfamily mpl\+::character}, {\ttfamily mpl\+::integer}.

The function {\ttfamily mpl\+::to\+\_\+string()} is specialized to provide a natural and readable string value of the wrappers. For example\+: \begin{DoxyVerb}#include "basic_types.hpp"
#include "to_string.hpp"

#include <iostream>

int main()
{
  using bool_value = mpl::boolean<true>;
  using char_value = mpl::character<'a'>;
  using integer_value = mpl::integer<10>;

  std::cout << mpl::to_string<bool_value>() << " ";
  std::cout << mpl::to_string<char_value>() << " ";
  std::cout << mpl::to_string<integer_value>();
}
\end{DoxyVerb}


Output\+: \begin{quote}
true a 10 \end{quote}


\paragraph*{Compile-\/time arithmetic\+:}

The library provides a set of default metafunctions to perform {\bfseries arithmetic, bitshift, logical, and comparison operations with the basic type wrappers}. Type casting is correctly performed in that computations to avoid signed-\/unsigned overflows and other related problems\+: \begin{DoxyVerb}#include "operators.hpp"
#include "basic_types.hpp"

int main()
{
  using a = mpl::uinteger<1>;
  using b = mpl::integer<2>;

  using c = mpl::add<a,b>; //c is mpl::integer<3>
}
\end{DoxyVerb}


\paragraph*{Expression templates\+: Operators overloading for a simple and more readable expression syntax}

Turbo overloads the most common operators to implement expression templates and provide, within type inspection through the \href{http://en.cppreference.com/w/cpp/language/decltype}{\tt `decltype` specifier}, the functions described above in a more confortable syntax. This is specially usefull when the expressions are complex. For example\+: \begin{DoxyVerb}#include "operators.hpp"
#include "basic_types.hpp"
#include "expressions.hpp"

int main()
{
  using x = mpl::integer<1>;
  using y = mpl::integer<2>;
  using z = mpl::integer<3>;

  //The following expression is equivalent to
  //mpl::add<mpl::add<mpl::mul<x,x>,mpl::mul<y,y>>,mpl::mul<z,z>>;:

  using square_length = decltype( x()*x() + y()*y() + z()*z() );
}
\end{DoxyVerb}


{\itshape N\+O\+T\+E\+: This is an example of the computation of the length of a 3d vector at compile-\/time. The example computes the square-\/length of the vector, because the {\ttfamily square\+\_\+root} function still is not implemented.}

\subsubsection*{Typelists}

Turbo implements variadic-\/template based typelists through the {\ttfamily mpl\+::list} class\+: \begin{DoxyVerb}#include "list.hpp"
#include "to_string.hpp"

using list = mpl::list<bool,char,int,float,double>;

int main()
{
  std::cout << mpl::to_string<list>() << std::endl;
}
\end{DoxyVerb}
 \begin{quote}
\mbox{[}bool,char,int,float,double\mbox{]} \end{quote}


\paragraph*{List operations\+:}

The library provides a set of list operations aviable for typelists\+: Splitting, concating, inserting, erasing, etc\+: \begin{DoxyVerb}#include "list.hpp"
#include "to_string.hpp"

using list = mpl::list<bool,char,int,float,double>;

using index = mpl::index_of<list,float>; //index is mpl::size_t<3>
using a = typename mpl::split<list,mpl::size_t<2>>::left;
using b = typename mpl::split<list,mpl::size_t<2>>::right;
using c = mpl::concat<b,a>;



int main()
{
  std::cout << mpl::to_string<list>() << std::endl;
  std::cout << mpl::to_string<a>() << std::endl;
  std::cout << mpl::to_string<b>() << std::endl;
  std::cout << mpl::to_string<c>() << std::endl;

}
\end{DoxyVerb}
 \begin{quote}
\mbox{[}bool,char,int,float,double\mbox{]} \mbox{[}bool,char,int\mbox{]} \mbox{[}float,double\mbox{]} \mbox{[}float,double,bool,char,int\mbox{]} \end{quote}


\paragraph*{Compile-\/time list sorting}

Using the list operations showed above {\bfseries Turbo implements a sorting metafunction\textsuperscript{1} which can be used to sort types with the specified criteria}. For example\+: \begin{DoxyVerb}#include "list.hpp"
#include "sort.hpp"

using list = mpl::list<double,char,float,int,

template<typename T , typename U>
using comparer = mpl::boolean<(sizeof(T) >= sizeof<(U))>;

using sorted_list = mpl::sort<list,comparer>;

int main()
{
  std::cout << mpl::to_string<sorted_list>() << std::endl;
}
\end{DoxyVerb}
 \begin{quote}
\mbox{[}double,int,float,char\mbox{]} \end{quote}


$\ast$\mbox{[}1\mbox{]} {\ttfamily mpl\+::sort} uses the quickosrt sorting algorithm by default, but this metafunction is parametrized to allow specifying other algorithms. The metafunction is defined as\+:$\ast$ \begin{DoxyVerb}template<
         typename LIST , 
         template<typename,typename> class COMPARER = mpl::greather_than , 
         template<typename,template<typename,typename>class> class ALGORITHM = mpl::qsort
        >
using mpl::sort = /* ... */
\end{DoxyVerb}
 {\itshape so you can implement your own sorting algorithm and pass it to the metafunction. For example\+:} \begin{DoxyVerb} template<typename LIST , template<typename,typename> class COMPARER>
 struct my_stupid_sorting_algorithm
 {
        using result = LIST;
 };

 using list = mpl::list<int,char,bool>;
 using sorted_list = mpl::sort<list,mpl::less_than,my_stupid_sorting_algorithm>;
\end{DoxyVerb}


\subsubsection*{Iterators and loops}

Turbo implements the iterator dessign pattern to provide an easy way to trasverse ranges or intervals, such as numeric intervals or a part of a typelist. The library defines three types of iterators\+:
\begin{DoxyItemize}
\item {\bfseries Forward iterators}\+: Are iterators dessigned to trasverse a range forwards (From begin to end).
\item {\bfseries Forward iterators}\+: This type of iterators are dessigned to trasverse a range form its end to its begin (In the backwards direction).
\item {\bfseries Bidirectional iterators \mbox{[}D\+E\+P\+R\+E\+C\+A\+T\+E\+D\mbox{]}}\+: Are iterators which can advance in any direction.
\end{DoxyItemize}

The library provides a set of metafunctions to work with iterators\+:
\begin{DoxyItemize}
\item {\bfseries Functions to get iterators}\+: Are functions to create iterators from things to trasverse it\+: {\ttfamily mpl\+::begin} , {\ttfamily mpl\+::end} , {\ttfamily mpl\+::rbegin} , {\ttfamily mpl\+::rend}.
\item {\bfseries Functions to manipulate iterators}\+: {\ttfamily mpl\+::next} , {\ttfamily mpl\+::previous}\mbox{[}D\+E\+P\+R\+E\+C\+A\+T\+E\+D\mbox{]}. All of the metafunctions above can be specialized to implement user-\/defined iterators. In fact the library provides specializations to work with typelists and integral numbers. For example\+: \begin{DoxyVerb}  #include "iterators.hpp"
  #include "numeric_iterators.hpp"
  #include "list.hpp"
  #include "basic_types.hpp"

  using list  = mpl::list<bool,char,int,float>;
  using begin = mpl::begin<list>;
  using end   = mpl::end<list>;

  /* A metafunction to print values of a typelist: */

  teplate<typename BEGIN , typename END>
  struct print_list
  {
    static void execute()
    {
        std::cout << mpl::to_string<typename BEGIN::value>() << std::endl;

        print_list<mpl::next<BEGIN>,END>::execute();
    }
  };

  template<typename END>
  struct print_list<END,END>
  {
    static void execute() {}
  };

  /* Possible usage: */

  using printer = print_list<mpl::begin<list> , mpl::end<list>>;
  using partial_printer = print_list<decltype( mpl::begin<list>() + mpl::size_t<2>() )  , mpl::end<list>>;


  int main()
  {
    printer::execute();
    std::cout << std::endl;
    partial_printer::execute();
  }
\end{DoxyVerb}
 \begin{quote}
bool char int float

int float \end{quote}

\end{DoxyItemize}

For integral types the library provides a set of utility functions to make iterators from integral values. The example above could be rewritten to work with unsigned ints\+: \begin{DoxyVerb}using printer = print_list<mpl::make_uinteger_backward_iterator<10> , mpl::make_uinteger_backward_iterator<0>>;
\end{DoxyVerb}
 \begin{quote}
10 \end{quote}
9 8 7 6 5 4 3 2 1

\paragraph*{Loops\+: for and for each}

A common problem with template-\/meta-\/programming and variadic templates is to execute an operation over a set of values (types). That leads to witing recursive metafunctions everytime we need to do that kind of operations.

{\bfseries Turbo provides the metaloops {\ttfamily mpl\+::for\+\_\+loop} and {\ttfamily mpl\+::for\+\_\+each} to simplify the implementation of that kind of things}. That loops works through iterators\+: What the loops do is to execute the specified {\itshape kernel} (The operation to be performed) through the range represented by the iterators. Finally, the loop returns the result.

\paragraph*{{\ttfamily mpl\+::for\+\_\+each}}

This loop is dessigned to apply the specified kernel to every type from a set of types, and return a typelist filled with the set of applications. Its equivalent \char`\"{}runtime\char`\"{} code is\+:

template$<$typename iterator\+\_\+type , typename result\+\_\+type$>$ std\+::vector$<$result\+\_\+type$>$ for\+\_\+each(iterator\+\_\+type begin , iterator\+\_\+type end , result\+\_\+type($\ast$)(typename iterator\+\_\+type\+::value\+\_\+type) kernel) \{ std\+::vector$<$result\+\_\+type$>$ output;

for( auto\& it = begin ; it != end ; ++it) output.\+push\+\_\+back( kernel($\ast$it) );

return output; \}

A kernel is a metafunction of the form\+: \begin{DoxyVerb} template<typename CURRENT>
 struct kernel
 {
  using result = /* Operation involving CURRENT */
 };
\end{DoxyVerb}
 In other words, a one parameter function.

What {\ttfamily mpl\+::for\+\_\+each} returns is the list of applications, that is, the set of {\ttfamily kernel\+::result} from each type. For example\+: \begin{DoxyVerb}using list = mpl::list<bool,char,float,int,double>;
using begin = mpl::begin<list>;
using end = mpl::end<list>;

//A kernel: It returns the size of the type specified
template<typename T>
struct compute_sizeof
{
  using result = mpl::size_t<sizeof(T)>;
};

using result = mpl::for_each<begin,end,compute_sizeof>;

int main()
{
  std::cout << mpl::to_string<result>() << std::endl;
}
\end{DoxyVerb}
 Output\+: \begin{quote}
\mbox{[}1,1,4,4,8\mbox{]} \end{quote}


Note that a kernel is a metafunction of one parameter which returns via a {\ttfamily result} alias. Thats exatly the signature of {\ttfamily mpl\+::function}, so you could use {\ttfamily mpl\+::function} to simplify the implementation of a kernel. The example above could be rewriten as\+: \begin{DoxyVerb}template<typename T>
using compute_sizeof = mpl::function<mpl::size_t<sizeof(T)>>;
\end{DoxyVerb}


In addition, you could specify a filter (A boolean predicate) to discard elements of the input which does not fullfill a requeriment. Following with the example above\+: \begin{DoxyVerb}...

template<typename T>
using filter = mpl::boolean<sizeof(T) % 2 == 0>;

using result = mpl::for_each<begin,end,compute_sizeof,filter>;

...
\end{DoxyVerb}
 Now the output is\+: \begin{quote}
\mbox{[}4,4,8\mbox{]} \end{quote}


\paragraph*{{\ttfamily mpl\+::for\+\_\+loop}}

{\ttfamily mpl\+::for\+\_\+loop} is dessigned to {\bfseries execute iterative computations}, in other words, does a loop over a range, and the kernel does computations over that range, storing the result and using the previous value of the result. This could be viewed as a for loop with an aux varialbe which stores the result of the computation, and the body of that loop (The kernel acts as the body of the loop). For example\+:

int result;

for(auto\& it = begin ; it != end ; ++it) \{ result = $\ast$it $\ast$ result; \}

So the kernel has two parameters\+: {\bfseries The current value of the iterator and the previous value of the result}\+:

template$<$typename C\+U\+R\+R\+E\+N\+T , typename P\+R\+E\+V\+I\+O\+U\+S\+\_\+\+R\+E\+S\+U\+L\+T$>$ struct kernel \{ using result = /$\ast$ ... $\ast$/ \}; The loop passes the {\ttfamily result} of the current kernel application to the next iteration. So {\bfseries the loop needs the initial value of the \char`\"{}aux variable\char`\"{}}. {\ttfamily mpl\+::for\+\_\+loop} is defined as follows\+:

template$<$typename B\+E\+G\+I\+N , typename E\+N\+D , typename I\+N\+I\+T\+I\+A\+L\+\_\+\+V\+A\+L\+U\+E , template$<$typename,typename$>$ class K\+E\+R\+N\+E\+L$>$ using for\+\_\+loop = /$\ast$...$\ast$/

In addition, a kernel of a for loop must define a public boolean constant that specifies if the loop should be aborted. In other words, {\bfseries the user could specify a break condition for the loop through the kernel}\+:

template$<$typename C\+U\+R\+R\+E\+N\+T , typename P\+R\+E\+V\+I\+O\+U\+S\+\_\+\+R\+E\+S\+U\+L\+T$>$ struct kernel \{ using result = /$\ast$ ... $\ast$/ static const bool abort = /$\ast$ ... $\ast$/ \};

An example of the use of {\ttfamily mpl\+::for\+\_\+loop} could be the computation of the summation of a range of numbers\+:

using begin = mpl\+::make\+\_\+uinteger\+\_\+forward\+\_\+iterator$<$0$>$; using end = mpl\+::make\+\_\+uinteger\+\_\+forward\+\_\+iterator$<$10$>$;

template$<$typename C\+U\+R\+R\+E\+N\+T\+\_\+\+V\+A\+L\+U\+E , typename P\+R\+E\+V\+I\+O\+U\+S\+\_\+\+R\+E\+S\+U\+L\+T$>$ struct kernel \+: public mpl\+::no\+\_\+abort\+\_\+kernel //\+This defines the abort flag as false \{ using result = mpl\+::add$<$\+P\+R\+E\+V\+I\+O\+U\+S\+\_\+\+R\+E\+S\+U\+L\+T,\+C\+U\+R\+R\+E\+N\+T\+\_\+\+V\+A\+L\+U\+E$>$; \};

using result = mpl\+::for\+\_\+loop$<$begin,end,mpl\+::uinteger$<$0$>$,kernel$>$;

int main() \{ std\+::cout $<$$<$ mpl\+::to\+\_\+string$<$result$>$() $<$$<$ std\+::cout; \} Output\+: \begin{quote}
45 \end{quote}


\subsubsection*{Compile-\/time fixed-\/point arithmetic}

Turbo implements decimal fixed-\/point arithmetic through the {\ttfamily mpl\+::fixed\+\_\+point} type. This type provides compile-\/time fixed-\/point arithmetic through specializations of the arithmetic metafunctions described above.

{\ttfamily mpl\+::fixed\+\_\+point} implements decimal fixed-\/point numbers with the specified precision (The number of digits which represent the fractional part of the number)\+: \begin{DoxyVerb}template<mpl::fixed_point_bits BITS , mpl::fixed_point_precission PRECISION>
struct fixed_point {};
\end{DoxyVerb}


By default {\ttfamily mpl\+::fixed\+\_\+point\+\_\+bits} is a {\ttfamily long long int}, that is, is 64 bits length. So {\ttfamily mpl\+::fixed\+\_\+point} {\bfseries could represent decimal numbers up to 19 digits}. Of course that 19 digits include the fractional digits. By default Turbo sets the precision of {\ttfamily mpl\+::fixed\+\_\+point} at 8 digits.

The way to instantiate fixed point numbers is tu cumbersome, because you have to take into account the precision of the number and provide the full integer number. For example\+:

using pi = mpl\+::fixed\+\_\+point$<$314150000,8$>$; //3,1415 with 8 digits precision

To deal with that problem, the library provides the alias {\ttfamily mpl\+::decimal}, which implements {\bfseries decimal scientific notation}\+: \begin{DoxyVerb}using pi = mpl::decimal<31415,-4>; //31415 x 10^-4 (3,1415)
\end{DoxyVerb}


Of course {\ttfamily mpl\+::fixed\+\_\+point} specializes {\ttfamily mpl\+::to\+\_\+string} \+: \begin{DoxyVerb}#include "fixed_point.hpp"
#include "expressions.hpp"
#include "to_string.hpp"

using pi      = mpl::decimal<314159265,-8>; //3,14159265
using radious = mpl::decimal<10>; //10
using circle_length = decltype( mpl::decimal<2>() * pi() * radious() );

int main()
{
 std::cout << "Radious: " << mpl::to_string<radious>() << std::endl;
 std::cout << "Circle length: " << mpl::to_string<circle_length>() << std::endl;
}
\end{DoxyVerb}
 \begin{quote}
Radious\+: 10 \end{quote}
Circle length\+: 62,831853

\subsubsection*{Trigonometric functions}

In addition to the arithmetic operations shared with the integral values, Turbo \href{https://github.com/Manu343726/Turbo/blob/dynamic_fixed_point/trigonometry.hpp}{\tt implements compile-\/time trigonometric functions such as sine and cosine through Taylor-\/\+Mc\+Laurin series}\+: \begin{DoxyVerb}#include "trigonometry.hpp"
#include "fixed_point.hpp"
#include "to_string.hpp"

using deg_0 = mpl::decimal<0>;
using deg_45 = decltype( math::pi() / mpl::decimal<4>() );
using deg_90 = decltype( math::pi() / mpl::decimal<2>() );

int main()
{
  std::cout << "sin(0º) = "  << mpl::to_string<math::sin<deg_0>>() << std::endl;
  std::cout << "sin(45º) = " << mpl::to_string<math::sin<deg_45>>() << std::endl;
  std::cout << "sin(90º) = " << mpl::to_string<math::sin<deg_90>>() << std::endl;

  std::cout << "cos(0º) = "  << mpl::to_string<math::cos<deg_0>>() << std::endl;
  std::cout << "cos(45º) = " << mpl::to_string<math::cos<deg_45>>() << std::endl;
  std::cout << "cos(90º) = " << mpl::to_string<math::cos<deg_90>>() << std::endl;
}
\end{DoxyVerb}
 \begin{quote}
sin(0º) = 0 \end{quote}
sin(45º) = 0,707107 sin(90º) = 1 cos(0º) = 1 cos(45º) = 0,07107 cos(90º) = 1e-\/08

As the example shows, the implementation has little precision errors ({\ttfamily cos(90º)} should be zero). Turbo uses a Mac\+Laurin series aproximation of 10 terms by default, but the arithmetric functions are parametrized to allow specifying the number of terms used in the aproximations\+: \begin{DoxyVerb}using cos_deg_90 = math::cos<deg_90,mpl::uinteger<200>>; //cos(90º) computed using 200 terms. 
\end{DoxyVerb}


\paragraph*{Square-\/root}

The library \href{https://github.com/Manu343726/Turbo/blob/dynamic_fixed_point/sqrt.hpp}{\tt implements a square root function}, {\ttfamily math\+::sqrt}, computing the value through the Newton's method to aproximate function roots\+:

using two = mpl\+::decimal$<$2$>$; using result = math\+::sqrt$<$two$>$;

int main() \{ std\+::cout $<$$<$ mpl\+::to\+\_\+string$<$result$>$() $<$$<$ std\+::endl; \} Output\+: \begin{quote}
1,4142 \end{quote}


\subsubsection*{Compile-\/time matrix algebra}

Turbo implements 3x3 and 4x4 matrices to provide {\bfseries compile-\/time matrix algebra}. It supports matrix addition, substraction, and multiplication. For example\+:

\#include \char`\"{}matrix3x3.\+hpp\char`\"{}

using unity = math\+::unity3x3$<$mpl\+::decimal$>$ using a = decltype( (unity() $\ast$ unity()) $\ast$ mpl\+::decimal$<$4$>$() ); using b = decltype( a() + a() );

int main() \{ std\+::cout $<$$<$ mpl\+::to\+\_\+string$<$b$>$() $<$$<$ std\+::endl; \} \begin{quote}
$\vert$ 8 0 0 $\vert$ \end{quote}
$\vert$ 0 8 0 $\vert$ $\vert$ 0 0 8 $\vert$

\subsubsection*{Compile-\/time 2d/3d transformations}

In adition to matrices, Turbo implements 2d/3d/4d vectors and provides {\bfseries transformation matrices} such as rotations, scales, translations, etc. For example\+:

\#include \char`\"{}matrix4x4.\+hpp\char`\"{} \#include \char`\"{}vector.\+hpp\char`\"{}

using v1 = math\+::vec3$<$mpl\+::decimal$<$1$>$ , mpl\+::decimal$<$1$>$ , mpl\+::decimal$<$1$>$$>$; using translation = mpl\+::vector$<$mpl\+::decimal$<$1$>$ , mpl\+::decimal$<$0$>$ , mpl\+::decimal$<$0$>$$>$; using angle = decltype(math\+::pi() / mpl\+::decimal$<$2$>$()); using transformation = decltype( math\+::translate$<$translation$>$() $\ast$ mpl\+::rotate$<$angle,math\+::x\+\_\+axis$>$() ); using v2 = decltype( transformation() $\ast$ v1() );

int main() \{ std\+::cout $<$$<$ mpl\+::to\+\_\+string$<$v1$>$() $<$$<$ std\+::endl; std\+::cout $<$$<$ mpl\+::to\+\_\+string$<$v2$>$() $<$$<$ std\+::endl; \} \begin{quote}
(1,1,1) \end{quote}
(2,1,-\/1)

\subsubsection*{Compile-\/time string manipulation}

Turbo explodes C++11 generalized constant expressions to manipulate raw strings and create types (metavariables) which the library can work with using template metaprogramming. For example\+: \begin{DoxyVerb}#include "string.hpp"
#include "to_string.hpp"

//TURBO_STRING_VARIABLE() macro defines a new string metavariable which holds the specified string:

TURBO_STRING_VARIABLE( hello , "hello " );
TURBO_STRING_VARIABLE( world , "world!" );

using hello_world = tml::concat<hello,world>;

int main()
{
    std::cout << tml::to_string<hello_world>() << std::endl;
}
\end{DoxyVerb}


\begin{quote}
hello world! \end{quote}


\subsubsection*{Future features\+:}

I'm currently working in a compile-\/time time manipulation library ({\ttfamily tml\+::chrono} namespace), based on the Standard {\ttfamily std\+::chrono} library. Also I'm working on compile-\/time random number generation facilities, using the features of {\ttfamily tml\+::chrono} as seed. 